\section{Conclusion}
\label{section:discussion}

This work introduces the formal concept of similarity inclusion dependencies (sINDs), extending traditional inclusion dependencies with a similarity measure.
%Thus, they allow for data errors and uncover hidden dependencies.
%Additionally, we present \sawfish, the first approach to efficiently discover such sINDs in a given dataset.
%Moreover, we investigate \sawfish's performance characteristics for a wide set of parameters and datasets.
%This section summarizes the main insights and discusses the current limitations of \sawfish.
%\subsection{Conclusion}
%In this work, we investigated multiple aspects of sINDs.
%First, we identified use cases for sINDs.
%These included the use cases of traditional INDs, such as foreign-key candidate and join partner discovery.
First, we identified use cases for sINDs, which include discovering foreign-key candidates and join partners.
%Additionally, sINDs can be used to determine erroneous data sources within a large data management system.
Second, we formalized an sIND definition that extends traditional INDs with an arbitrary similarity measure.
Third, we presented \sawfish, the first efficient approach to automatically discover sINDs from data.
It finds all unary sINDs based on the edit-distance and the Jaccard similarity measure.
\sawfish combines approaches of traditional IND discovery and string similarity joins with a novel sliding-window approach and lazy candidate validation. %discovering unary sINDs based on the edit-distance similarity measure.
Fourth, we evaluated \sawfish, showing that it scales well in the number of rows, and in the number of columns.
%Furthermore, we observed that \sawfish does not require more main memory than the size of the largest column to run efficiently.
%However, we also discovered some limitations that we address in the next section.
Compared to a baseline implementation, we outperformed it by a factor of up to~6.5.
Finally, we examined the sINDs discovered by \sawfish and observed real-world examples indicating joinability.

%\subsection{Limitations and Future Work}
%\label{section:discussion:future}
%While \sawfish can discover sINDs efficiently, it relies on certain assumptions.
%These include the requirement that each column must fit entirely into main memory.
%In the future, this might be avoided with better locality sensitive hashing techniques, so the bucketing process can adopt the hash-partitioning scheme of \algorithmName{Binder}.
%Thus, there would be no need for a main memory requirement.
%However, since \sawfish needs to fit only a single column into main memory, the real-world impact of this constraint is limited.
%
%Another limiting aspect of \sawfish is its runtime on larger datasets and higher edit distances.
While sIND discovery is a harder problem than traditional IND discovery, the runtime could be further improved by multithreading or distributing the process.
As \algorithmName{Sindy}~\cite{dursch2019eval} demonstrated, distribution can significantly improve the performance.
However, we observed that a single column or even a single sIND candidate can dominate the runtime.
Therefore, it is not trivial to scale \sawfish's approach to multiple threads or nodes.
Further future work shall extend \sawfish to discover n-ary sINDs.% and to use similarity measures beyond the edit distance.
%
% Besides the execution characteristics, \sawfish's results are also limited in some aspects.
% First, \sawfish can discover only unary sINDs.
% However, the sIND definition also allows for n-ary sINDs.
% Thus, \sawfish can be extended to discover n-ary sINDs, too.
% This massively increases the search space, since we would need to process not only pairs of columns, but rather pairs of column lists that can form an sIND.
% Therefore, this could be combined with faster validation algorithms to keep the execution time reasonable.
%
%Second, \sawfish supports only the edit distance as a similarity measure. 
%While this is a good starting point, there are certainly other interesting similarity measures.
%To work with other edit-based similarity measures, large parts of \sawfish can be reused.
%For example, the deduplication and the length splitting of the preprocessing are helpful for all edit-based similarity measures.
%Additionally, we can define tighter pruning rules for other measures.
%For example, the Hamming distance is defined only on similar sized strings, so we could improve our length pruning~\cite{hamming1950error}.

% Our index in the main discovery step is specialized on the edit distance, so it would need to be adapted for other similarity measures.
% Moreover, to use token-based similarity measures, there would be more necessary changes.
% The preprocessing would need to split the input values into tokens and perform pruning by their token count.
% The main discovery implementation needs to be modified for the selected similarity measure.
% However, the general structure of \sawfish could be applied.
% This includes preprocessing the input data, generating sIND candidates, and validating the candidates.
% \sawfish includes easily adaptable functions that reliably complete the tasks.

% There might be more opportunities in the future to extend traditional data dependencies with similarity measures.
% In this regard, \sawfish provides a foundation that can be used for further ideas.